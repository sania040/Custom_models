# Custom Machine Learning Models from Scratch

This notebook contains end-to-end implementations of key machine learning algorithms **without using scikit-learn or prebuilt ML libraries**. Every model is coded from the ground up, including manual loss functions, optimizers, and vectorization logic.

## âœ… What's Included

### 1. Naive Bayes Classifier
- Custom tokenizer & word counter
- Prior and conditional probabilities
- Laplace smoothing
- Log probability calculations
- Applied to SMS Spam dataset and IMDb sentiment classification

### 2. Linear Regression
- Manual implementation of MSE loss
- Gradient descent
- Fitted line visualization

### 3. Logistic Regression
- Sigmoid function
- Binary cross-entropy loss
- Manual gradient descent optimization
- Prediction and accuracy evaluation
- Optional probability plots

---

## ðŸ§  Why This Exists

The goal of this notebook is to deeply understand how machine learning models work under the hood by:
- Rebuilding key algorithms from scratch
- Visualizing each step
- Debugging through the math
- Applying the models to real datasets

## ðŸ’¡ How to Use

1. Clone this repo or download the notebook
2. Follow each model section (Naive Bayes â†’ Linear â†’ Logistic)
3. Modify code or datasets to explore further

> If youâ€™re learning ML, building it from scratch helps far more than copy-pasting from a library.

## ðŸ“‚ Datasets Used
- [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)
- [IMDb Movie Reviews](https://ai.stanford.edu/~amaas/data/sentiment/)
- Simple synthetic regression data (generated in-notebook)

---

## ðŸš€ Next Steps

- Extend to multiclass classification
- Add regularization support
- Wrap models in classes for reuse

---

## ðŸ“¬ Questions or Feedback?
Open an issue or connect with me on [LinkedIn](your-linkedin-url-here).

---
